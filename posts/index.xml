<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Himanshu Panwar</title>
    <link>https://myselfhimanshu.github.io/posts/</link>
    <description>Recent content in Posts on Himanshu Panwar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 29 Mar 2020 22:22:22 +0530</lastBuildDate>
    
	<atom:link href="https://myselfhimanshu.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Convolutional Neural Network Part 2 : Neural Architecture</title>
      <link>https://myselfhimanshu.github.io/posts/cnn_02/</link>
      <pubDate>Sun, 29 Mar 2020 22:22:22 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/cnn_02/</guid>
      <description>In this tutorial, we will be training the network on MNIST dataset. We&amp;rsquo;ll try to understand neural network architecture.
The most important thing to understand in deep learning is what is our network learning which requires understanding of the network architecture. The below architecture is not meant to give us very good score. In this post we&amp;rsquo;ll focus on few more concepts and then jump into pytorch-101.
To understand the basic terminologies of CNN building blocks.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Network Part 1 : Basic Concepts</title>
      <link>https://myselfhimanshu.github.io/posts/cnn_01/</link>
      <pubDate>Sun, 22 Mar 2020 22:22:22 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/cnn_01/</guid>
      <description>I am starting this series of posts, where in we&amp;rsquo;ll build on background knowledge of neural networks and explore what CNNs are. We will cover from basic understanding of how and what is CNN, augumentation techniques, architectures of CNNs, training an object detection model and more. Before moving forward, I recommend you to learn some basic terminologies of neural networks and how they work.
Iâ€™ll try to explain the concepts in layman terms.</description>
    </item>
    
    <item>
      <title>Sequence Model Part 3 : Sequence models &amp; Attention mechanism</title>
      <link>https://myselfhimanshu.github.io/posts/sequence_learning_3/</link>
      <pubDate>Sun, 17 Nov 2019 20:54:18 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/sequence_learning_3/</guid>
      <description>Various Sequence to Sequence Architecture Basic Model
Let&amp;rsquo;s start with a machine translation model of converting french to english: Given a sequence X we need the output y. Here we have a network called as encoder with gru or lstm blocks which feeds in french words one at a time and outputs a vector that will represent our input french sentence. This vector can be feeded to another network called as decoder and can be trained to output the translated sentence one word at a time.</description>
    </item>
    
    <item>
      <title>Sequence Model Part 2 : Word Embeddings</title>
      <link>https://myselfhimanshu.github.io/posts/sequence_learning_2/</link>
      <pubDate>Sun, 10 Nov 2019 10:22:19 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/sequence_learning_2/</guid>
      <description>Natural Language Processing and Word Embeddings Word Embeddings Word Representations
Word Embeddings is the way of representing the words. It lets us understand the analogies between words like (&amp;ldquo;king&amp;rdquo; and &amp;ldquo;queen&amp;rdquo;) or (&amp;ldquo;man&amp;rdquo; and &amp;ldquo;woman&amp;rdquo;).
In the previous post we represented the words with a one-hot vector. One of the weakness of one-hot vector representation is that it treats a word as a thing and doesn&amp;rsquo;t allow to generalize across the words.</description>
    </item>
    
    <item>
      <title>Sequence Model Part 1 : RNNS</title>
      <link>https://myselfhimanshu.github.io/posts/sequence_learning_1/</link>
      <pubDate>Sun, 03 Nov 2019 21:46:34 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/sequence_learning_1/</guid>
      <description>Recurrent Neural Networks Some Examples
   Example X (input) Y(output) Type     Speech Recognition wave sequence text sequence sequence to sequence   Music Generation nothing or integer wave sequence one to sequence   Sentiment Classification text sequence integer(label) sequence to one   Machine Translation text sequence text sequence sequence to sequence   Video Activity Recognition video frames label(activity) sequence to one    All these problems have different types of input and output formats.</description>
    </item>
    
    <item>
      <title>Setting Up Paperspace for Deep Learning</title>
      <link>https://myselfhimanshu.github.io/posts/setting_paperspace_dl/</link>
      <pubDate>Tue, 01 Jan 2019 14:26:21 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/setting_paperspace_dl/</guid>
      <description>Step by Step Guide to Setup Paperspace Machine for Deep Learning  Create an Account : paperspace.com Sign up with my promo code for Paperspace to get a $10 credit! Add in credit card information (required, even if you have a promo code) Go to https://www.paperspace.com/console/machines and click New Machine. Choose a region near to you. Choose Ubuntu 16.04 in Linux Templates. Create new P4000 machine with at least 50 GB storage and a public IP and turn off Auto Snapshot (just for saving).</description>
    </item>
    
    <item>
      <title>Fibonacci Numbers Series</title>
      <link>https://myselfhimanshu.github.io/posts/fibonacci-numbers-series/</link>
      <pubDate>Tue, 06 Nov 2018 12:31:51 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/fibonacci-numbers-series/</guid>
      <description>Fibonacci Number Fibonacci sequence: $F_0=0$, $F_1=1$, and $F_i=F_{i-1}+F_{i-2}$. Given an integer n, find the nth Fibonacci number $F_n$
Input format : The input consists of a single integer n.
Output format : Output $F_n$.
Constraints : $0&amp;lt;=n&amp;lt;=45$
CODE
a = [0,1] for i in range(2,46): a.append(a[i-1] + a[i-2]) def calc_fib(n): return a[n] n = int(input()) print(calc_fib(n)) Last Digit of Large Fibonacci Number Given an integer n, find the last digit of the nth Fibonacci number $F_n$(that is, $F_n$ mod 10)</description>
    </item>
    
    <item>
      <title>My First Blog Post : Algorithm</title>
      <link>https://myselfhimanshu.github.io/posts/my-first-post/</link>
      <pubDate>Mon, 05 Nov 2018 19:20:13 +0530</pubDate>
      
      <guid>https://myselfhimanshu.github.io/posts/my-first-post/</guid>
      <description>Here&amp;rsquo;s a small python code.
Sum of two digits Compute the sum of two single digit numbers
Input format : Integers a and b on the same line (separated by a space).
Output format : The sum of a and b.
Constraints : $0&amp;lt;=a,b&amp;lt;=9$
#Uses python3 import sys input = sys.stdin.read() tokens = input.split() a = int(tokens[0]) b = int(tokens[1]) print(a+b) Maximum Pairwise Product Find the maximum product of two distinct numbers in a sequence of non-negative integers.</description>
    </item>
    
  </channel>
</rss>